{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub search result crawler\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pageStart = 1\n",
    "pageEnd = 100\n",
    "\n",
    "with open('../Dataset/Offboarding url list.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"URL\"])\n",
    "    for page in tqdm(range(pageStart, pageEnd+1)):\n",
    "        url = \"https://github.com/search?p={}&q=offboarding&type=Issues\".format(page)\n",
    "        html_doc = requests.get(url).content\n",
    "        soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "        table = soup.find(\"div\", {\"id\": \"issue_search_results\"})\n",
    "        table = table.div\n",
    "        topic = \"\"\n",
    "        result = []\n",
    "\n",
    "        for s in table.findAll(\"div\", {\"class\": \"issue-list-item d-flex py-4 hx_hit-issue public\"}):\n",
    "            topic = s.find(\"div\",{\"class\": \"ml-1 flex-auto\"}).find(\"div\",{\"class\": \"f4 text-normal markdown-title\"}).find('a', href=True)\n",
    "            writer.writerow([\"https://github.com/{}\".format(topic['href'])])\n",
    "\n",
    "        if page % 9 == 0:\n",
    "            print(\"Sleeping for 1 miniute...\")\n",
    "            time.sleep(60)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2990c2bb4b324d239e416e1de10b5644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract JSON from GitHub API\n",
    "import json, csv\n",
    "from tqdm.notebook import tqdm\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "with open('../Dataset/Sample dataset.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for row in tqdm(reader):\n",
    "        url = row[1]\n",
    "        token = url.split(\"/\")\n",
    "        filename = token[4] + \"#\" + token[5] + \"#\" + token[7] + \".json\"\n",
    "        req = Request(url)\n",
    "        req.add_header('Authorization', 'token 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')\n",
    "        data = json.loads(urlopen(req).read().decode())\n",
    "        with open('../JSON Dataset/'+filename, 'w') as json_file:\n",
    "            json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a9fe93312f4580b551e221d5ed2230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Extract topic from JSON file\n",
    "import os, glob, json, csv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "parent_dir = '../JSON Dataset/'\n",
    "\n",
    "\n",
    "with open('../Result/Sample dataset with title.csv', 'w') as outFile:\n",
    "    writer = csv.writer(outFile)\n",
    "    with open('../Dataset/Sample dataset.csv', 'r') as inFile:\n",
    "        reader = csv.reader(inFile)\n",
    "        column = next(reader)\n",
    "        column.append('Title')\n",
    "        writer.writerow(column)\n",
    "        \n",
    "        for row in tqdm(reader):\n",
    "            url = row[1]\n",
    "            token = url.split(\"/\")\n",
    "            file = parent_dir + token[4] + \"#\" + token[5] + \"#\" + token[7] + \".json\"\n",
    "            data = open(file,\"r\", encoding=\"utf8\", errors='ignore')\n",
    "            data = json.load(data)\n",
    "            row.append(data['title'])\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
